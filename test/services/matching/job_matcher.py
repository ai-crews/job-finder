import json
import os
from typing import List, Dict, Any
from datetime import datetime, timedelta


class JobMatcher:
    def __init__(self, data_folder_path: str):
        self.data_folder = data_folder_path
        self.job_data = self._load_all_job_data()
        self.company_name_mapping = self._build_company_mapping()
        print(f"ì´ {len(self.job_data)}ê°œì˜ ì±„ìš©ê³µê³ ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    def _build_company_mapping(self) -> Dict[str, List[str]]:
        """ì‹¤ì œ íŒŒì¼ì˜ company_nameê³¼ ì‚¬ìš©ì ì„ íƒ íšŒì‚¬ëª… ê°„ì˜ ë§¤í•‘ êµ¬ì¶•"""
        mapping = {

            # í•œí™” ê·¸ë£¹
            "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤": ["í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤"],
            "í•œí™”ì‹œìŠ¤í…œ/ë°©ì‚°": ["í•œí™”ì‹œìŠ¤í…œ/ë°©ì‚°", "í•œí™”ì‹œìŠ¤í…œ", "í•œí™”ì‹œìŠ¤í…œ/ICT"],
            "í•œí™”ì†”ë£¨ì…˜/ì¼€ë¯¸ì¹¼": ["í•œí™”ì†”ë£¨ì…˜/ì¼€ë¯¸ì¹¼", "í•œí™”ì†”ë£¨ì…˜", "í•œí™”ì¼€ë¯¸ì¹¼"],
            "í•œí™”ì†”ë£¨ì…˜/íì…€": ["í•œí™”ì†”ë£¨ì…˜/íì…€", "í•œí™”ì†”ë£¨ì…˜", "í•œí™”íì…€"],
            "í•œí™”ìƒëª…": ["í•œí™”ìƒëª…"],
            "í•œí™”ì†í•´ë³´í—˜": ["í•œí™”ì†í•´ë³´í—˜"],
            
            # ë„¤ì´ë²„ ê·¸ë£¹
            "NAVER WEBTOON": ["NAVER WEBTOON", "ë„¤ì´ë²„ì›¹íˆ°"],

            # ì¹´ì¹´ì˜¤ ê·¸ë£¹
            "ì¹´ì¹´ì˜¤": ["ì¹´ì¹´ì˜¤","Kakao"],
        }
        return mapping
    
    def _load_all_job_data(self) -> List[Dict]:
        """ëª¨ë“  ì±„ìš©ê³µê³  JSON íŒŒì¼ ë¡œë“œ"""
        job_data = []
        print(f"ë°ì´í„° í´ë” ê²½ë¡œ: {self.data_folder}")
        
        for root, dirs, files in os.walk(self.data_folder):
            print(f"íƒìƒ‰ ì¤‘ì¸ í´ë”: {root}")
            print(f"í•˜ìœ„ í´ë”ë“¤: {dirs}")
            print(f"íŒŒì¼ë“¤: {files}")
            
            for filename in files:
                if filename.endswith(".json"):
                    file_path = os.path.join(root, filename)
                    print(f"JSON íŒŒì¼ ë¡œë”© ì‹œë„: {file_path}")
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            company_name = data.get("company_name", "")
                            print(f"  ì„±ê³µ: íšŒì‚¬ëª…={company_name}")
                            
                            if "company_name" not in data or not data["company_name"]:
                                company_from_filename = (
                                    self._extract_company_from_filename(filename)
                                )
                                if company_from_filename:
                                    data["company_name_from_file"] = (
                                        company_from_filename
                                    )
                                    print(f"  íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•œ íšŒì‚¬ëª…: {company_from_filename}")
                            job_data.append(data)
                    except Exception as e:
                        print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {filename}: {e}")
        
        print(f"ì´ ë¡œë“œëœ ê³µê³  ìˆ˜: {len(job_data)}")
        return job_data

    def _extract_company_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ"""
        parts = filename.replace(".json", "").split("_")
        if len(parts) >= 2:
            return parts[0]
        return ""

    def is_preferred_company(
        self, target_companies: List[str], job_company: str
    ) -> bool:
        """í¬ë§ê¸°ì—… ì—¬ë¶€ í™•ì¸"""
        if not target_companies or not job_company:
            return False

        # 1. ì§ì ‘ ë§¤ì¹­
        if job_company in target_companies:
            return True

        # 2. ë§¤í•‘ í…Œì´ë¸”ì„ í†µí•œ ë§¤ì¹­
        for target_company in target_companies:
            mapped_names = self.company_name_mapping.get(target_company, [])
            if isinstance(mapped_names, str):
                mapped_names = [mapped_names]

            for mapped_name in mapped_names:
                if mapped_name == job_company:
                    return True

            # ë¶€ë¶„ ë§¤ì¹­
            for mapped_name in mapped_names:
                if (
                    mapped_name.lower() in job_company.lower()
                    or job_company.lower() in mapped_name.lower()
                ):
                    return True

        # 3. ê¸°ë³¸ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
        job_company_clean = job_company.lower().replace(" ", "").replace("/", "")
        for target_company in target_companies:
            target_clean = target_company.lower().replace(" ", "").replace("/", "")
            if target_clean in job_company_clean or job_company_clean in target_clean:
                return True

            if "/" in job_company:
                company_base = job_company.split("/")[0].lower().replace(" ", "")
                if target_clean in company_base or company_base in target_clean:
                    return True

        return False

    def count_nulls(self, job_dict: Dict) -> int:
        """ì±„ìš©ê³µê³ ì˜ NULL ê°œìˆ˜ ê³„ì‚°"""
        check_fields = [
            "min_education_level",
            "min_experience_level",
            "employment_type",
        ]
        return sum(
            1
            for field in check_fields
            if not job_dict.get(field) or job_dict.get(field) == "í™•ì¸ë¶ˆê°€"
        )

    def get_job_role_priority(self, target_jobs: List[str], job: Dict) -> int:
        """ì§ë¬´ ìš°ì„ ìˆœìœ„ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ìš°ì„ ìˆœìœ„ ë†’ìŒ)"""
        for i, target_job in enumerate(target_jobs, 1):
            if target_job and self._is_job_match(job, target_job):
                return i
        return 5

    def get_priority(self, user_values: List[str], job_value: str) -> int:
        """ê³µí†µ ìš°ì„ ìˆœìœ„ ê³„ì‚° í•¨ìˆ˜"""
        if not job_value or job_value == "í™•ì¸ë¶ˆê°€":
            return 2
        if not user_values:
            return 3
        return 1 if job_value in user_values else 3

    def apply_basic_filters(
        self, user_data: Dict, job_postings: List[Dict]
    ) -> List[Dict]:
        """1ë‹¨ê³„ í•„í„°ë§: ì‹ ì… ê³µê³ ë§Œ ì¶”ì¶œ"""
        filtered_jobs = []
        career_preference = user_data.get(
            "ì°¾ê³  ê³„ì‹  ê³µê³ ì˜ ê²½ë ¥ ì¡°ê±´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", ""
        )

        for job in job_postings:
            experience_level = job.get("min_experience_level", "")
            if "ì‹ ì…" in career_preference:
                if experience_level in ["ì‹ ì…", "í™•ì¸ë¶ˆê°€", ""]:
                    filtered_jobs.append(job)
            else:
                filtered_jobs.append(job)
        return filtered_jobs

    def filter_by_employment_type(
        self, user_data: Dict, job_postings: List[Dict]
    ) -> List[Dict]:
        """2ë‹¨ê³„ í•„í„°ë§: ê³ ìš©í˜•íƒœ"""
        filtered_jobs = []
        target_employment_types = self._parse_employment_types(
            user_data.get("í¬ë§ ê³ ìš© í˜•íƒœ (ë³µìˆ˜ì„ íƒ)", "")
        )

        for job in job_postings:
            employment_type = job.get("employment_type", "")
            if (
                not employment_type
                or employment_type == "í™•ì¸ë¶ˆê°€"
                or not target_employment_types
                or employment_type in target_employment_types
            ):
                filtered_jobs.append(job)
        return filtered_jobs

    def filter_by_job_role(
        self, user_data: Dict, job_postings: List[Dict]
    ) -> List[Dict]:
        """3ë‹¨ê³„ í•„í„°ë§: ì§ë¬´"""
        filtered_jobs = []
        target_jobs = [
            user_data.get("í¬ë§ ì§ë¬´ 1ìˆœìœ„ (í•„ìˆ˜ì‘ë‹µ)", ""),
            user_data.get("í¬ë§ ì§ë¬´ 2ìˆœìœ„ ", ""),  # ê³µë°± í¬í•¨!
            user_data.get("í¬ë§ ì§ë¬´ 3ìˆœìœ„ ", ""),  # ê³µë°± í¬í•¨!
        ]
        target_jobs = [job.strip() for job in target_jobs if job.strip()]

        for job in job_postings:
            if not target_jobs or self._is_job_match(job, target_jobs):
                filtered_jobs.append(job)
        return filtered_jobs

    def _is_education_match(self, user_edu_list, job_education):
        for user_edu in user_edu_list:
            if user_edu in job_education:
                return True
            if ("í•™ì‚¬" in user_edu and "4ë…„" in user_edu) and (
                "ëŒ€í•™" in job_education and "4ë…„" in job_education
            ):
                return True
        return False

    def filter_by_education(
        self, user_data: Dict, job_postings: List[Dict]
    ) -> List[Dict]:
        filtered_jobs = []
        user_education = user_data.get(
            "ì°¾ê³  ê³„ì‹  ê³µê³ ì˜ í•™ë ¥ ì¡°ê±´ì„ ì„ íƒí•´ì£¼ì„¸ìš”. (ì¡¸ì—…ì˜ˆì •ìë„ ì„ íƒ ê°€ëŠ¥, ë³µìˆ˜ì„ íƒ)",
            "",
        )
        user_edu_list = [
            edu.strip() for edu in user_education.split(",") if edu.strip()
        ]

        for job in job_postings:
            education = job.get("min_education_level", "")
            if (
                not education
                or education == "í•™ë ¥_í™•ì¸ë¶ˆê°€"
                or not user_edu_list
                or self._is_education_match(user_edu_list, education)
            ):
                filtered_jobs.append(job)
        return filtered_jobs

    def match_jobs_for_user(self, user_data: Dict, top_n: int = 100) -> List[Dict]:
        """ì‚¬ìš©ìì—ê²Œ ë§ëŠ” ì±„ìš©ê³µê³  ë§¤ì¹­ - ë””ë²„ê¹… ë²„ì „"""
        print("=== í•„í„°ë§ ì‹œì‘ ===")

        # ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ
        target_companies = self._extract_target_companies(user_data)
        target_jobs = [
            user_data.get("í¬ë§ ì§ë¬´ 1ìˆœìœ„ (í•„ìˆ˜ì‘ë‹µ)", ""),
            user_data.get("í¬ë§ ì§ë¬´ 2ìˆœìœ„ ", ""),
            user_data.get("í¬ë§ ì§ë¬´ 3ìˆœìœ„ ", ""),
        ]
        target_jobs = [job.strip() for job in target_jobs if job.strip()]
        target_employment_types = self._parse_employment_types(
            user_data.get("í¬ë§ ê³ ìš© í˜•íƒœ (ë³µìˆ˜ì„ íƒ)", "")
        )

        print(f"ì‚¬ìš©ì í¬ë§ ì§ë¬´: {target_jobs}")
        print(f"ì‚¬ìš©ì í¬ë§ íšŒì‚¬: {target_companies}")
        print(f"ì‚¬ìš©ì í¬ë§ ê³ ìš©í˜•íƒœ: {target_employment_types}")

        # ğŸ” ì¹´ì¹´ì˜¤ ê³µê³  ì¶”ì  ì‹œì‘
        kakao_jobs_initial = [job for job in self.job_data if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"\nğŸ” ì´ˆê¸° ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_jobs_initial)}ê°œ")
        for job in kakao_jobs_initial:
            print(f"   - {job.get('company_name')}: {job.get('processed_position_name')} ({job.get('employment_type')})")

        # ë‹¨ê³„ë³„ í•„í„°ë§
        step1_jobs = self.apply_basic_filters(user_data, self.job_data)
        print(f"1ë‹¨ê³„(ê²½ë ¥) í›„: {len(step1_jobs)}ê°œ ê³µê³ ")
        
        # ğŸ” 1ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ 
        kakao_step1 = [job for job in step1_jobs if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"ğŸ” 1ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_step1)}ê°œ")

        step2_jobs = self.filter_by_employment_type(user_data, step1_jobs)
        print(f"2ë‹¨ê³„(ê³ ìš©í˜•íƒœ) í›„: {len(step2_jobs)}ê°œ ê³µê³ ")
        
        # ğŸ” 2ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ 
        kakao_step2 = [job for job in step2_jobs if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"ğŸ” 2ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_step2)}ê°œ")

        step3_jobs = self.filter_by_job_role(user_data, step2_jobs)
        print(f"3ë‹¨ê³„(ì§ë¬´) í›„: {len(step3_jobs)}ê°œ ê³µê³ ")
        
        # ğŸ” 3ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ 
        kakao_step3 = [job for job in step3_jobs if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"ğŸ” 3ë‹¨ê³„ í›„ ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_step3)}ê°œ")
        if kakao_step3:
            for job in kakao_step3:
                print(f"   - ë§¤ì¹­ëœ ì¹´ì¹´ì˜¤ ê³µê³ : {job.get('processed_position_name')}")

        final_jobs = self.filter_by_education(user_data, step3_jobs)
        print(f"4ë‹¨ê³„(í•™ë ¥) í›„: {len(final_jobs)}ê°œ ê³µê³ ")
        
        # ğŸ” ìµœì¢… ì¹´ì¹´ì˜¤ ê³µê³ 
        kakao_final = [job for job in final_jobs if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"ğŸ” ìµœì¢… í•„í„°ë§ í›„ ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_final)}ê°œ")

        if not final_jobs:
            print("í•„í„°ë§ í›„ ì¶”ì²œí•  ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤")
            return []

        # í¬ë§ê¸°ì—… ë¶„ë¦¬
        preferred_jobs = []
        other_jobs = []

        for job in final_jobs:
            company_name = job.get("company_name", "") or job.get("company_name_from_file", "")
            is_preferred = self.is_preferred_company(target_companies, company_name)
            
            # ğŸ” ì¹´ì¹´ì˜¤ ê³µê³  í¬ë§ê¸°ì—… ë§¤ì¹­ í™•ì¸
            if "ì¹´ì¹´ì˜¤" in company_name:
                print(f"ğŸ” ì¹´ì¹´ì˜¤ í¬ë§ê¸°ì—… ë§¤ì¹­ í™•ì¸: '{company_name}' -> {is_preferred}")
                print(f"   í¬ë§ê¸°ì—… ë¦¬ìŠ¤íŠ¸: {target_companies}")
            
            if is_preferred:
                preferred_jobs.append(job)
                if "ì¹´ì¹´ì˜¤" in company_name:
                    print(f"âœ… ì¹´ì¹´ì˜¤ í¬ë§ê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜ë¨: {company_name}")
            else:
                other_jobs.append(job)

        print(f"í¬ë§ê¸°ì—… ê³µê³ : {len(preferred_jobs)}ê°œ, ê¸°íƒ€ ê³µê³ : {len(other_jobs)}ê°œ")

        # ì •ë ¬
        def sort_key(job):
            user_education = user_data.get(
                "ì°¾ê³  ê³„ì‹  ê³µê³ ì˜ í•™ë ¥ ì¡°ê±´ì„ ì„ íƒí•´ì£¼ì„¸ìš”. (ì¡¸ì—…ì˜ˆì •ìë„ ì„ íƒ ê°€ëŠ¥, ë³µìˆ˜ì„ íƒ)",
                "",
            )
            user_edu_list = [
                edu.strip() for edu in user_education.split(",") if edu.strip()
            ]

            return (
                self.count_nulls(job),
                self.get_job_role_priority(target_jobs, job),
                self.get_priority(user_edu_list, job.get("min_education_level", "")),
                self.get_priority(
                    target_employment_types, job.get("employment_type", "")
                ),
                job.get("company_name", ""),
            )

        preferred_jobs.sort(key=sort_key)
        other_jobs.sort(key=sort_key)
        top_jobs = (preferred_jobs + other_jobs)[:top_n]

        # ğŸ” ìµœì¢… ê²°ê³¼ì—ì„œ ì¹´ì¹´ì˜¤ ê³µê³  í™•ì¸
        kakao_in_result = [job for job in top_jobs if "ì¹´ì¹´ì˜¤" in job.get("company_name", "")]
        print(f"ğŸ” ìµœì¢… ê²°ê³¼ì— í¬í•¨ëœ ì¹´ì¹´ì˜¤ ê³µê³ : {len(kakao_in_result)}ê°œ")

        print(f"ì¶”ì²œ ì™„ë£Œ: {len(top_jobs)}ê°œ ê³µê³  ì„ ì •")

        return [
            {
                "job": job,
                "is_preferred_company": self.is_preferred_company(
                    target_companies,
                    job.get("company_name", "")
                    or job.get("company_name_from_file", ""),
                ),
                "score": 100,
            }
            for job in top_jobs
        ]

    def _parse_employment_types(self, employment_str: str) -> List[str]:
        """ê³ ìš©í˜•íƒœ ë¬¸ìì—´ íŒŒì‹±"""
        if not employment_str:
            return []
        return [emp.strip() for emp in employment_str.split(",") if emp.strip()]

    def _extract_target_companies(self, user_data: Dict) -> List[str]:
        """ì‚¬ìš©ìê°€ ê´€ì‹¬ìˆëŠ” íšŒì‚¬ë“¤ ì¶”ì¶œ"""
        companies = []
        company_mappings = {
            "ì‚¼ì„±": {
                "key": "ì‚¼ì„± ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "ì‚¼ì„±ì „ì DXë¶€ë¬¸",
                    "ì‚¼ì„±ì „ì DSë¶€ë¬¸",
                    "ì‚¼ì„±SDI",
                    "ì‚¼ì„±ì „ê¸°",
                    "ì‚¼ì„±SDS",
                    "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤",
                    "ì‚¼ì„±ìƒëª…",
                    "ì‚¼ì„±í™”ì¬",
                    "ì‚¼ì„±ì¤‘ê³µì—…",
                    "ì‚¼ì„±E&A",
                    "ì‚¼ì„±ë¬¼ì‚° ê±´ì„¤ë¶€ë¬¸",
                    "ì‚¼ì„±ë¬¼ì‚° ìƒì‚¬ë¶€ë¬¸",
                    "ì‚¼ì„±ë¬¼ì‚° ë¦¬ì¡°íŠ¸ë¶€ë¬¸",
                    "ì‚¼ì„±ë¬¼ì‚° íŒ¨ì…˜ë¶€ë¬¸",
                    "í˜¸í…”ì‹ ë¼",
                    "ì œì¼ê¸°íš",
                    "ì—ìŠ¤ì›",
                ],
            },
            "SK": {
                "key": "SK ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "SK í…”ë ˆì½¤",
                    "SK í•˜ì´ë‹‰ìŠ¤",
                    "SK ì´ë…¸ë² ì´ì…˜",
                    "SK ë°”ì´ì˜¤íŒœ",
                    "SK ì‹¤íŠ¸ë¡ ",
                    "SKC",
                    "SK ìŠ¤í€˜ì–´",
                    "SK ì£¼ì‹íšŒì‚¬",
                ],
            },
            "í˜„ëŒ€ìë™ì°¨": {
                "key": "í˜„ëŒ€ìë™ì°¨ ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ê¸°ì•„", "í˜„ëŒ€ëª¨ë¹„ìŠ¤"],
            },
            "LG": {
                "key": "LG ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "LGì´ë…¸í…",
                    "LGí™”í•™",
                    "LGìƒí™œê±´ê°•",
                    "LGì—ë„ˆì§€ì†”ë£¨ì…˜",
                    "LGìœ í”ŒëŸ¬ìŠ¤",
                    "LG AIì—°êµ¬ì›",
                    "LG CNS",
                ],
            },
            "ë¡¯ë°": {
                "key": "ë¡¯ë° ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "ë¡¯ë°ì¹ ì„±ìŒë£Œ",
                    "ë¡¯ë°ë°±í™”ì ",
                    "ë¡¯ë°ë§ˆíŠ¸ â€¢ ë¡¯ë°ìŠˆí¼",
                    "ë¡¯ë°í•˜ì´ë§ˆíŠ¸",
                    "ë¡¯ë°í™ˆì‡¼í•‘",
                    "ë¡¯ë°ë©´ì„¸ì ",
                    "ë¡¯ë°í˜¸í…”",
                    "ë¡¯ë°ì›”ë“œ",
                    "ë¡¯ë°ê¸€ë¡œë²Œë¡œì§€ìŠ¤",
                    "ëŒ€í¥ê¸°íš",
                    "ë¡¯ë°ë¬¼ì‚°",
                    "ë¡¯ë°ì´ë…¸ë² ì´íŠ¸",
                    "ë¡¯ë°ë Œíƒˆ",
                    "ë¡¯ë°ì¼€ë¯¸ì¹¼",
                    "ë¡¯ë°ê±´ì„¤",
                    "ë¡¯ë°ì—ë„ˆì§€ë¨¸í‹°ë¦¬ì–¼ì¦ˆ",
                ],
            },
            "í•œí™”": {
                "key": "í•œí™” ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤",
                    "í•œí™”ì‹œìŠ¤í…œ/ë°©ì‚°",
                    "í•œí™”ì†”ë£¨ì…˜/ì¼€ë¯¸ì¹¼",
                    "í•œí™”ì†”ë£¨ì…˜/íì…€",
                    "í•œí™”ìƒëª…",
                    "í•œí™”ì†í•´ë³´í—˜",
                ],
            },
            "CJ": {
                "key": "CJ ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "CJì œì¼ì œë‹¹",
                    "CJí”„ë ˆì‹œì›¨ì´",
                    "CJ ENM",
                    "CJ CGV",
                    "CJëŒ€í•œí†µìš´",
                    "CJì˜¬ë¦¬ë¸Œë„¤íŠ¸ì›ìŠ¤",
                    "CJì˜¬ë¦¬ë¸Œì˜",
                    "TVING",
                ],
            },
            "ì¹´ì¹´ì˜¤": {
                "key": "ì¹´ì¹´ì˜¤ ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤ë±…í¬", "ì¹´ì¹´ì˜¤í˜ì´", "ì¹´ì¹´ì˜¤ëª¨ë¹Œë¦¬í‹°"],
            },
            "ì¿ íŒ¡": {
                "key": "ì¿ íŒ¡ ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ì¿ íŒ¡"],
            },
            "ë„¤ì´ë²„": {
                "key": "NAVER ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": [
                    "NAVER",
                    "NAVER Cloud",
                    "NAVER WEBTOON",
                    "NAVER FINANCIAL",
                    "NAVERWORKS",
                ],
            },
            "ì‹ í•œê¸ˆìœµ": {
                "key": "ì‹ í•œê¸ˆìœµê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ì‹ í•œì€í–‰", "ì‹ í•œì¹´ë“œ", "ì‹ í•œíˆ¬ìì¦ê¶Œ", "ì‹ í•œìƒëª…"],
            },
            "KBê¸ˆìœµ": {
                "key": "KBê¸ˆìœµê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["KBêµ­ë¯¼ì€í–‰", "KBêµ­ë¯¼ì¹´ë“œ", "KBì¦ê¶Œ", "KBì†í•´ë³´í—˜"],
            },
            "í•˜ë‚˜ê¸ˆìœµ": {
                "key": "í•˜ë‚˜ê¸ˆìœµê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["í•˜ë‚˜ì€í–‰", "í•˜ë‚˜ì¹´ë“œ", "í•˜ë‚˜ì¦ê¶Œ", "í•˜ë‚˜ì†í•´ë³´í—˜"],
            },
            "ìš°ë¦¬ê¸ˆìœµ": {
                "key": "ìš°ë¦¬ê¸ˆìœµê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ìš°ë¦¬ì€í–‰", "ìš°ë¦¬ì¹´ë“œ", "ìš°ë¦¬ì¦ê¶Œ"],
            },
            "í† ìŠ¤": {
                "key": "í† ìŠ¤ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["í† ìŠ¤", "í† ìŠ¤ë±…í¬", "í† ìŠ¤í˜ì´ë¨¼ì¸ ", "í† ìŠ¤ì¦ê¶Œ"],
            },
            "ìš°ì•„í•œí˜•ì œë“¤": {
                "key": "ìš°ì•„í•œí˜•ì œë“¤ ê·¸ë£¹ì—ì„œ ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "companies": ["ìš°ì•„í•œí˜•ì œë“¤"],
            },
        }

        for group_name, group_info in company_mappings.items():
            group_selection = user_data.get(group_info["key"], "")
            if group_selection and group_selection.strip():
                if "ì „ì²´" in group_selection:
                    companies.extend(group_info["companies"])
                    print(
                        f"'{group_name} ì „ì²´' ì„ íƒë¨ â†’ {len(group_info['companies'])}ê°œ íšŒì‚¬ ì¶”ê°€"
                    )
                else:
                    selected = [
                        c.strip() for c in group_selection.split(",") if c.strip()
                    ]
                    companies.extend(selected)
                    print(f"'{group_name}' ê°œë³„ ì„ íƒ â†’ {selected}")

        return list(set(companies))

    def _is_job_match(self, job: Dict, target_jobs: List[str]) -> bool:
        """ì§ë¬´ ë§¤ì¹­ ì—¬ë¶€ íŒë‹¨"""
        if not target_jobs:
            return True

        processed_position = job.get("processed_position_name", "")
        for target_job in target_jobs:
            if not target_job:
                continue
            if processed_position and processed_position != "ë¯¸ë¶„ë¥˜":
                if self._simple_match(processed_position, target_job):
                    return True
        return False

    def _simple_match(self, job_field: str, target_job: str) -> bool:
        """ë‹¨ìˆœ ë¬¸ìì—´ ë§¤ì¹­"""
        if not job_field or not target_job:
            return False
        return target_job.lower().replace(" ", "") in job_field.lower().replace(" ", "")
